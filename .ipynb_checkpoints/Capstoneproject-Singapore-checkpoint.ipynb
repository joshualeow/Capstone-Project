{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Capstone Project: Private Property Neighborhoods in Singapore</h1>\n",
    "<h1>This notebook will be mainly used for the capstone project</h1>\n",
    "<h4>Includes using location data in determining the suitable neighbourhoods, Clustering the neighbourhoods in Toronto</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Capstone Project Course!\n"
     ]
    }
   ],
   "source": [
    "print('Hello Capstone Project Course!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopy in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (2.1.0)\n",
      "Requirement already satisfied: geographiclib<2,>=1.49 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geopy) (1.50)\n",
      "Requirement already satisfied: folium==0.5.0 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: branca in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from folium==0.5.0) (0.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from folium==0.5.0) (2.11.2)\n",
      "Requirement already satisfied: requests in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from folium==0.5.0) (2.24.0)\n",
      "Requirement already satisfied: six in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from folium==0.5.0) (1.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from jinja2->folium==0.5.0) (1.1.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->folium==0.5.0) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->folium==0.5.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->folium==0.5.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->folium==0.5.0) (2020.6.20)\n",
      "Requirement already satisfied: geocoder in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (1.38.1)\n",
      "Requirement already satisfied: future in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geocoder) (0.18.2)\n",
      "Requirement already satisfied: click in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geocoder) (7.1.2)\n",
      "Requirement already satisfied: six in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geocoder) (1.15.0)\n",
      "Requirement already satisfied: requests in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geocoder) (2.24.0)\n",
      "Requirement already satisfied: ratelim in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from geocoder) (0.1.6)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->geocoder) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->geocoder) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->geocoder) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from requests->geocoder) (2020.6.20)\n",
      "Requirement already satisfied: decorator in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from ratelim->geocoder) (4.4.2)\n",
      "Requirement already satisfied: seaborn in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (0.11.0)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joshualeow/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy\n",
    "!pip install folium==0.5.0\n",
    "!pip install geocoder\n",
    "!pip install seaborn\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from geopy.geocoders import Nominatim \n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "!conda install -c conda-forge folium=0.5.0 --yes\n",
    "\n",
    "import folium # map rendering library\n",
    "import requests\n",
    "import geocoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above I have used BeautifulSoup to extract data from the wikipedia website\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape wikipedia page\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate1.csv\")\n",
    "df2 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate2.csv\")\n",
    "df3 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate3.csv\")\n",
    "df4 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate4.csv\")\n",
    "df5 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate5.csv\")\n",
    "df6 =pd.read_csv(\"/Users/joshualeow/Desktop/DataCondo/DataPrivate6.csv\")\n",
    "\n",
    "frames = [df1, df2, df3, df4, df5, df6]\n",
    "\n",
    "df_merged = pd.concat(frames)\n",
    "\n",
    "df_merged.columns = df_merged.iloc[0]\n",
    "df_merged = df_merged[1:]\n",
    "\n",
    "\n",
    "df_merged.rename(columns={'level_0': 'S/N', 'level_1': 'ProjectName'}, inplace=True)\n",
    "df_merged = df_merged.reset_index(drop=False).rename(columns={'level_0':'S/N', 'level_1':'ProjectName', 'level_2':'StreetName','level_3':'Type','level_4':'PostalDistrict','level_5':'MarketSegment','level_6':'Tenure','level_7':'TypeOfSale','level_8':'NoUnits','level_9':'Price','level_10':'NettPrice','level_11':'Sqft','level_12':'TypeOfArea','level_13':'FloorLevel','level_14':'UnitPrice','level_15':'DateOfSale'})\n",
    "\n",
    "\n",
    "print(df_merged.columns.tolist())\n",
    "\n",
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_of_sn = df_merged['StreetName'].unique().tolist()\n",
    "list_of_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_lat = []\n",
    "prop_long = []\n",
    "for i in range(0, len(list_of_sn)):\n",
    "    query_address = list_of_sn[i]\n",
    "    query_string = 'https://developers.onemap.sg/commonapi/search?searchVal='+str(query_address)+'&returnGeom=Y&getAddrDetails=Y'\n",
    "    resp = requests.get(query_string)\n",
    "\n",
    "    data_prop=json.loads(resp.content)\n",
    "    \n",
    "    if data_prop['found'] != 0:\n",
    "        prop_lat.append(data_prop[\"results\"][0][\"LATITUDE\"])\n",
    "        prop_long.append(data_prop[\"results\"][0][\"LONGITUDE\"])\n",
    "\n",
    "        print (str(query_address)+\",Lat: \"+data_prop['results'][0]['LATITUDE'] +\" Long: \"+data_prop['results'][0]['LONGITUDE'])\n",
    "\n",
    "    else:\n",
    "        prop_lat.append('NotFound')\n",
    "        prop_long.append('NotFound')\n",
    "        print (\"No Results\")\n",
    "        \n",
    "# With reference from https://towardsdatascience.com/working-with-apis-in-data-science-explore-bit-rent-theory-in-singapores-hdb-resale-market-d7760fdfc601\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proplocation = pd.DataFrame({\n",
    "    'StreetName': list_of_sn,\n",
    "    'latitude': prop_lat,\n",
    "    'longitude': prop_long})\n",
    "\n",
    "proplocation.head(10)\n",
    "proplocation['StreetName'].head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now I will combine the df_merged and proplocation dataframes into one.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata = pd.merge(df_merged, proplocation, how=\"left\", on=[\"StreetName\"])\n",
    "\n",
    "#data cleaning, dropping rows with strings\n",
    "\n",
    "outerdata = outerdata[~outerdata['Price'].isin(['Price ($)'])] #drop rows with strings\n",
    "\n",
    "outerdata[\"Price\"]= pd.to_numeric(outerdata[\"Price\"], downcast=\"float\")\n",
    "outerdata['NoUnits'] = pd.to_numeric(outerdata['NoUnits'], downcast=\"float\")\n",
    "outerdata.head()\n",
    "\n",
    "\n",
    "    \n",
    "outerdata['NoUnits'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outerdata.dropna(subset=[\"latitude\"], axis=0, inplace = True)\n",
    "outerdata.dropna(subset=[\"StreetName\"], axis=0, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "outerdata['Price'] = outerdata['Price'].div(outerdata['NoUnits']) #To divide prices buy number of units for consistency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outerdata[outerdata['NoUnits'] > 1].index.values) # checking if prices were divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata.iloc[6031:6035] # checking if prices were divided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pywaffle\n",
    "from pywaffle.waffle import Waffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outermean = outerdata.groupby(\"StreetName\", as_index=False)[\"Price\"].mean()\n",
    "\n",
    "\n",
    "\n",
    "mapdata = pd.merge(outermean, proplocation, on=[\"StreetName\"])\n",
    "mapdata = mapdata.drop([mapdata.index[0]])\n",
    "mapdata = mapdata.drop([mapdata.index[233]])\n",
    "mapdata = mapdata.drop([mapdata.index[304]])\n",
    "mapdata = mapdata.drop([mapdata.index[709]]) #dropping value that are not found coordinates\n",
    "mapdata[\"latitude\"]= pd.to_numeric(mapdata[\"latitude\"], downcast=\"float\")\n",
    "mapdata[\"longitude\"]= pd.to_numeric(mapdata[\"longitude\"], downcast=\"float\") #to enable folium to work, convert from object\n",
    "\n",
    "\n",
    "\n",
    "outermean.iloc[830:838]\n",
    "mapdata.shape\n",
    "# why are some of the street names missing?\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floorcount = outerdata.groupby('FloorLevel').count()\n",
    "floorcount = floorcount.drop([floorcount.index[0]])\n",
    "floorcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightgreen', 'pink', 'aqua', 'azure', 'darkgreen', 'darkblue', 'orchid', 'lime', 'lavender', 'brown', 'beige', 'crimson']\n",
    "explode_list = [0.1, 0, 0, 0, 0.1, 0.1 ,0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1] # ratio for each continent with which to offset each wedge.\n",
    "\n",
    "floorcount['StreetName'].plot(kind='pie',\n",
    "                            figsize=(20, 15),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,         # turn off labels on pie chart\n",
    "                            pctdistance=1.12,    # the ratio between the center of each pie slice and the start of the text generated by autopct \n",
    "                            colors=colors_list,  # add custom colors\n",
    "                            explode=explode_list # 'explode' lowest 3 continents\n",
    "                            )\n",
    "\n",
    "# scale the title up by 12% to match pctdistance\n",
    "plt.title('Percentage of Floor Levels of Private Residential Property (Based on Transactions)', y=1.12) \n",
    "\n",
    "plt.axis('equal') \n",
    "\n",
    "# add legend\n",
    "plt.legend(labels=floorcount.index, loc='upper left') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "groupfloor = outerdata[['FloorLevel', 'Price']]\n",
    "\n",
    "groupfloor = groupfloor.groupby(['FloorLevel'],as_index=False).mean()\n",
    "groupfloor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# drop rows: df[~df.C.str.contains(\"XYZ\")]\n",
    "\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.regplot(x=\"Price\", y = \"FloorLevel\", data=groupfloor)\n",
    "\n",
    "plt.ylim(0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata.groupby('Tenure').count()\n",
    "\n",
    "grouptenure = outerdata[['Tenure', 'Price']]\n",
    "\n",
    "grouptenure = grouptenure.groupby(['Tenure'],as_index=False).mean()\n",
    "\n",
    "freehold = grouptenure[grouptenure['Tenure'].str.contains(\"Freehold\")]\n",
    "freehold\n",
    "\n",
    "grouptenure=grouptenure[~grouptenure['Tenure'].isin(['Freehold'])]\n",
    "#grouptenure[['leaseperiod']] = grouptenure.Tenure.str.split(\" \",expand= True,)\n",
    "\n",
    "tenurenew = grouptenure['Tenure'].str.extract('([^a-zA-Z]+)([a-zA-Z]+)', expand=True) #to extract the numbers from alphabets\n",
    "tenurenew.columns = ['numberyears', 'text']\n",
    "\n",
    "\n",
    "tenuredata = pd.concat([tenurenew, grouptenure], axis=1).reindex(tenurenew.index)\n",
    "tenuremean = tenuredata.groupby(['numberyears'], as_index=False).mean()\n",
    "#tenuremean = mapdata.drop([mapdata.index[709]])\n",
    "tenuremean.replace(' ', np.nan, inplace = True)\n",
    "tenuremean.dropna(inplace=True)\n",
    "tenuremean[\"numberyears\"]= pd.to_numeric(tenuremean[\"numberyears\"], downcast=\"float\")\n",
    "\n",
    "\n",
    "tenuremean = tenuremean.sort_values(by=['numberyears'], ascending=True)\n",
    "tenuremean = tenuremean.set_index('numberyears')\n",
    "tenuremean = tenuremean.append(freehold.iloc[0])\n",
    "tenuremean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbar = tenuremean.plot(kind='bar')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.title(\"Price based on Tenure\")\n",
    "tbar.set_xlabel(\"Number of Years\")\n",
    "tbar.set_ylabel('Price ($Millions)')\n",
    "plt.rcParams[\"figure.figsize\"] = [15,10]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'Singapore, Singapore'\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"sg_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "print('The geograpical coordinate of Singapore are {}, {}.'.format(latitude, longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_singapore = folium.Map(location=[latitude, longitude], zoom_start=11)\n",
    "\n",
    "\n",
    "for latitude, longitude, StreetName, Price in zip(mapdata['latitude'], mapdata['longitude'], mapdata['StreetName'], mapdata['Price']):\n",
    "    label = '{}, {}'.format(Price, StreetName)\n",
    "    label = folium.Popup(label, parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [latitude, longitude],\n",
    "        radius=5,\n",
    "        popup=label,\n",
    "        color='blue',\n",
    "        fill=True,\n",
    "        fill_color='#3186cc',\n",
    "        fill_opacity=0.7,\n",
    "        parse_html=False).add_to(map_singapore)  \n",
    "    \n",
    "map_singapore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Notice that the private apartments/condominiums are largely located in the southern part of Singapore.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = 'K4YZ0DCCW2EWL5RQQTVEP0FU4C43H3JOWDIYETH2XDMSN45C' \n",
    "CLIENT_SECRET = 'Y14VBD21PTLCX1OIIEO3EBMTNPH3ATIIZFT3BQCGKUAS5LH3' \n",
    "VERSION = '20180605' \n",
    "LIMIT = 100 \n",
    "\n",
    "print('Your credentails:')\n",
    "print('CLIENT_ID: ' + CLIENT_ID)\n",
    "print('CLIENT_SECRET:' + CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outerdata.loc[0, 'StreetName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "street_latitude = outerdata.loc[0, 'latitude'] # street latitude value\n",
    "street_longitude = outerdata.loc[0, 'longitude'] # street longitude value\n",
    "\n",
    "street_name = outerdata.loc[0, 'StreetName'] # neighborhood name\n",
    "\n",
    "print('Latitude and longitude values of {} are {}, {}.'.format(street_name, \n",
    "                                                               street_latitude, \n",
    "                                                               street_longitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT = 100\n",
    "radius = 500\n",
    "\n",
    "\n",
    "url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "    CLIENT_ID, \n",
    "    CLIENT_SECRET, \n",
    "    VERSION, \n",
    "    street_latitude, \n",
    "    street_longitude, \n",
    "    radius, \n",
    "    LIMIT)\n",
    "url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get(url).json()\n",
    "results\n",
    "\n",
    "def get_category_type(row):\n",
    "    try:\n",
    "        categories_list = row['categories']\n",
    "    except:\n",
    "        categories_list = row['venue.categories']\n",
    "        \n",
    "    if len(categories_list) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return categories_list[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues = results['response']['groups'][0]['items']\n",
    "    \n",
    "nearby_venues = json_normalize(venues) # flatten JSON\n",
    "\n",
    "# filter columns\n",
    "filtered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\n",
    "nearby_venues =nearby_venues.loc[:, filtered_columns]\n",
    "\n",
    "# filter the category for each row\n",
    "nearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n",
    "\n",
    "# clean columns\n",
    "nearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n",
    "\n",
    "nearby_venues.head()\n",
    "\n",
    "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n",
    "    \n",
    "    venues_list=[]\n",
    "    for name, lat, lng in zip(names, latitudes, longitudes):\n",
    "        print(name)\n",
    "            \n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            lat, \n",
    "            lng, \n",
    "            radius, \n",
    "            LIMIT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "        \n",
    "        # return only relevant information for each nearby venue\n",
    "        venues_list.append([(\n",
    "            name, \n",
    "            lat, \n",
    "            lng, \n",
    "            v['venue']['name'], \n",
    "            v['venue']['location']['lat'], \n",
    "            v['venue']['location']['lng'],  \n",
    "            v['venue']['categories'][0]['name']) for v in results])\n",
    "\n",
    "    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n",
    "    nearby_venues.columns = ['Street', \n",
    "                  'Street Latitude', \n",
    "                  'Street Longitude', \n",
    "                  'Venue', \n",
    "                  'Venue Latitude', \n",
    "                  'Venue Longitude', \n",
    "                  'Venue Category']\n",
    "    \n",
    "    return(nearby_venues)\n",
    "\n",
    "nearby_venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singapore_venues = getNearbyVenues(names=mapdata['StreetName'],\n",
    "                                   latitudes=mapdata['latitude'],\n",
    "                                   longitudes=mapdata['longitude']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "singapore_venues.head\n",
    "singapore_venues = singapore_venues.str.replace('B', 'Bishopsgate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venuesper = singapore_venues.groupby('Street').count()\n",
    "\n",
    "print('There are {} uniques categories.'.format(len(singapore_venues['Venue Category'].unique())))\n",
    "venuesper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "singapore_onehot = pd.get_dummies(singapore_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n",
    "\n",
    "# add neighborhood column back to dataframe\n",
    "singapore_onehot['Street'] = singapore_venues['Street'] \n",
    "\n",
    "# move neighborhood column to the first column\n",
    "fixed_columns = [singapore_onehot.columns[-1]] + list(singapore_onehot.columns[:-1])\n",
    "singapore_onehot = singapore_onehot[fixed_columns]\n",
    "\n",
    "singapore_onehot.shape\n",
    "\n",
    "singapore_grouped = singapore_onehot.groupby('Street').mean().reset_index()\n",
    "singapore_grouped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def return_most_common_venues(row, num_top_venues):\n",
    "    row_categories = row.iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    \n",
    "    return row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "columns = ['Street']\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        columns.append('{}th Most Common Venue'.format(ind+1))\n",
    "\n",
    "# create a new dataframe\n",
    "street_venues_sorted = pd.DataFrame(columns=columns)\n",
    "street_venues_sorted['Street'] = singapore_grouped['Street']\n",
    "\n",
    "for ind in np.arange(singapore_grouped.shape[0]):\n",
    "    street_venues_sorted.iloc[ind, 1:] = return_most_common_venues(singapore_grouped.iloc[ind, :], num_top_venues)\n",
    "\n",
    "street_venues_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set number of clusters\n",
    "kclusters = 5\n",
    "\n",
    "singapore_grouped_clustering = singapore_grouped.drop('Street', 1)\n",
    "\n",
    "# run k-means clustering\n",
    "kmeans = KMeans(n_clusters=kclusters, random_state=0).fit(singapore_grouped_clustering)\n",
    "\n",
    "# check cluster labels generated for each row in the dataframe\n",
    "kmeans.labels_[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "table=soup.find_all('table')\n",
    "\n",
    "table\n",
    "\n",
    "\n",
    "table_contents=[]\n",
    "table=soup.find('table')\n",
    "for row in table.findAll('td'):\n",
    "    cell = {}\n",
    "    if row.span.text=='Not assigned':\n",
    "        pass\n",
    "    else:\n",
    "        cell['PostalCode'] = row.p.text[:3]\n",
    "        cell['Borough'] = (row.span.text).split('(')[0]\n",
    "        cell['Neighborhood'] = (((((row.span.text).split('(')[1]).strip(')')).replace(' /',',')).replace(')',' ')).strip(' ')\n",
    "        table_contents.append(cell)\n",
    "        \n",
    "\n",
    "# print(table_contents)\n",
    "df=pd.DataFrame(table_contents)\n",
    "df['Borough']=df['Borough'].replace({'Downtown TorontoStn A PO Boxes25 The Esplanade':'Downtown Toronto Stn A',\n",
    "                                             'East TorontoBusiness reply mail Processing Centre969 Eastern':'East Toronto Business',\n",
    "                                             'EtobicokeNorthwest':'Etobicoke Northwest','East YorkEast Toronto':'East York/East Toronto',\n",
    "                                             'MississaugaCanada Post Gateway Processing Centre':'Mississauga'})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
